{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "eVapOJSPD9OX"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-cd2a7e7facb5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## Imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimize\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "## Imports\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.optimize as resol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kTxz0YSgC6Zv"
   },
   "source": [
    "# **Projet mathématique - Partie II**\n",
    "\n",
    "## **Chaînes de Markov et temps d’arrêt**\n",
    "\n",
    "Lien du sujet : https://drive.google.com/file/d/1EPzGk_UQ5y2bjMI8iTgFYmfPHWRwlQMf/view\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "-hrY_VRUC4-Z"
   },
   "outputs": [],
   "source": [
    "def sim_dis(p, x, M):\n",
    "    y=np.zeros(M, dtype=int)\n",
    "    for k in range(M):\n",
    "        u=np.random.uniform(0,1)\n",
    "        S,i=0,0\n",
    "        while S<u:\n",
    "            S+=p[i]\n",
    "            i+=1\n",
    "        j=i-1\n",
    "        y[k] = x[j]\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lZHDMVxiWSsn"
   },
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BdUtRHLiWhR1"
   },
   "source": [
    "##### 1.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 593
    },
    "id": "p_t4qk7rOCmP",
    "outputId": "fc37044a-a9f8-4cb0-dd99-f1d741161f09"
   },
   "outputs": [],
   "source": [
    "N = 100\n",
    "X0 = 5\n",
    "a = 10\n",
    "prob = 0.5\n",
    "M = 1000\n",
    "\n",
    "fig = plt.figure(figsize=(8,3),dpi=200)\n",
    "\n",
    "def ruine_du_joueur(N, X0, a, p, to_print=False) : \n",
    "  # Initialisation\n",
    "  n = 0 #nombre de tours\n",
    "  Xn = X0 #argent du joueur à l'étape n\n",
    "  L_Xn = [X0]\n",
    "  # Tours\n",
    "  while (Xn!=0 and Xn!=a and n<N) :\n",
    "    n+=1\n",
    "    Xn += sim_dis([1-p,p], [-1,1], 1)[0]\n",
    "    L_Xn.append(Xn)\n",
    "  if to_print :\n",
    "    plt.step(range(n+1),L_Xn)\n",
    "  return [n,Xn]\n",
    "\n",
    "L = []\n",
    "sum = 0\n",
    "for i in range (M) :\n",
    "  L.append(ruine_du_joueur(N, X0, a, prob, i<10))\n",
    "  sum+=(L[i][1]==a)\n",
    "plt.xlabel(\"Richesse\")\n",
    "plt.ylabel(\"Tour\")\n",
    "plt.title(\"Evolution de la richesse du joueur (p=\"+str(prob)+\")\")\n",
    "plt.show()\n",
    "p = sum / M\n",
    "print(\"p =\",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8RmhVO3Om-G-"
   },
   "source": [
    "Soit $(X_n)_{n \\in \\mathbb N}$ la chaîne de Markov décrivant la richesse du joueur dans le jeu \\og la ruine du joueur \\fg.\n",
    "\n",
    "Soit le temps d'arrêt $\\tau_{0,a}$ défini tel que :\n",
    "$$\n",
    "\\tau_{0,a} = \\min \\, \\{ n \\geqslant 0 \\; | \\; X_n = a \\text{ ou } X_n = 0 \\}\n",
    "$$\n",
    "\n",
    "On supposera ici que $\\mathbb{P}(\\tau_{0,a}<\\infty)=1$, et on définit pour tout $x\\in\\{0,...,a\\}$ :\n",
    "$$\n",
    "f(x)=\\mathbb{P}(X_{\\tau_{0,a}}=a|X_0=x)\n",
    "$$\n",
    "\n",
    "On sait que $f(0)=0$ et que $f(a)=1$, et que pour tout entier $i$ tel que $0<i<a$, on a :\n",
    "\\begin{align*}\n",
    "    f(i)&=\\mathbb{P}(X_{\\tau_{0,a}}=a \\, | \\,X_0=i) \\\\\n",
    "    &=\\sum_{j=0}^a\\mathbb{P}(X_{\\tau_{0,a}}=a \\, | \\, X_0=i,X_1=j) \\, \\mathbb{P}(X_1=j \\,|\\, X_0=i) \\tag{loi des probabilités totales}\\\\\n",
    "    &=\\sum_{j=0}^a f(j)\\,p(i,j) \\tag{propriété de Markov}\\\\\n",
    "    &=\\sum_{j=1}^{a-1} f(j)\\,p(i,j) \\; +p(i,a) \\tag{car $f(0)=0$ et $f(a)=1$}\n",
    "\\end{align*}\n",
    "\n",
    "D'où le système suivant :\n",
    "$$\n",
    "\\boxed{\n",
    "\\forall i \\in \\mathbb N,\\, 0 < i < a, \\quad f(i) = p(i,a) + \\sum_{j=1}^{a-1} f(j) \\, p(i,j)\n",
    "}\n",
    "$$\n",
    "\n",
    "On peut alors écrire ce système sous forme matricielle, en notant $b = \\left( p(i,a) \\right)_{0<i<a}$, $x=(f(i))_{0<i<a}$ et $M=(p(i,j))_{0<i,j<a}$ :\n",
    "\\begin{align*}\n",
    "    \\forall i \\in \\mathbb N,\\, 0 < i < a, \\quad &f(i) = p(i,a) + \\sum_{j=1}^{a-1} f(j) \\, p(i,j) \\\\\n",
    "    \\Longrightarrow \\quad & x = b + Mx \\\\\n",
    "    \\Longrightarrow \\quad &\\boxed{\\left[I_{a-1}-M\\right]x = b}\n",
    "\\end{align*}\n",
    "\n",
    "Or, $P = (p(i,j))_{0\\leq i,j \\leq a}$ est une matrice stochastique à coefficients non nuls (déjà vu dans la première partie du projet). Donc, on peut en déduire que la matrice $A = \\left[ I_{a-1}-M \\right]$ est \\textbf{une matrice à diagonale strictement dominante}.\n",
    "\n",
    "En effet, on a : \n",
    "\\begin{equation*}\n",
    "    \\forall i \\in [1, a-1], \\quad a_{i,i} = 1 - p(i,i) \\qquad \\text{et} \\qquad \\sum_{\\underset{j \\neq i}{j=1}}^{a-1} a_{i,j} = \\sum_{\\underset{j\\neq i}{j = 1}}^{a-1} p(i,j)\n",
    "\\end{equation*}\n",
    "\n",
    "Et par définition de $P$, comme $\\displaystyle \\sum_{j=0}^a p(i,j) = 1$ avec $p(i,0), p(i,a) > 0$, on en déduit que :\n",
    "\\begin{align*}\n",
    "    &\\forall i \\in [1, a-1], \\quad 1 - p(i,i) = \\sum_{\\underset{j \\neq i}{j=0}}^a p(i,j) > \\sum_{\\underset{j \\neq i}{j=1}}^{a-1} p(i,j) \\\\\n",
    "    \\Longrightarrow \\quad &\\forall i \\in [1, a-1], \\quad |a_{i,i}| > \\sum_{\\underset{j \\neq i}{j=1}}^{a-1} a_{i,j}\n",
    "\\end{align*}\n",
    "\n",
    "Donc, d'après le \\textbf{lemme d'Hadamard}, on en déduit que \\textbf{$A$ est inversible}. Donc, \\textbf{notre système admet une unique solution}.\\\\\n",
    "\n",
    "Le système matricielle peut être facilement résolue grâce à Python :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xUQ-oQ2SK2iw",
    "outputId": "f672a114-bbf8-482a-9930-d9e79d01eb02"
   },
   "outputs": [],
   "source": [
    "def resolv(a,p) :\n",
    "  # Matrice M\n",
    "  M = np.zeros([a-1,a-1])\n",
    "  for i in range (a-2) :\n",
    "      M[i,i+1]=p\n",
    "      M[i+1,i]=1-p\n",
    "  A = np.eye(a-1) - M\n",
    "  # Vecteur b\n",
    "  b = [0 for i in range(a-1)]\n",
    "  b[a-2] = p\n",
    "  b =  np.array(b)\n",
    "  # Résolution\n",
    "  return np.linalg.solve(A, b)\n",
    "x = resolv(a,prob)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yNkMi7P0QBZ5"
   },
   "source": [
    "Dans le cadre fixé par le sujet, c'est-à-dire $a=10$, $p = 0.5$, on a :\n",
    "\n",
    "$$\n",
    "\\forall x\\in[1,a-1], \\quad \\mathbb{P}(X_{\\tau_{0,a}}=a \\,|\\, X_0=x)=\\dfrac{x}a\n",
    "$$\n",
    "\n",
    "Avec évidemment $\\mathbb{P}(X_{\\tau_{0,a}}=a \\,|\\, X_0=0)= 0 \\;$ et $\\; \\mathbb{P}(X_{\\tau_{0,a}}=a \\,|\\, X_0=a) = 1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7LcJaGW6w96n"
   },
   "source": [
    "Nous venons donc de déterminer la \\textit{vraie} probabilité associée à $\\mathbb{P}(X_{\\tau_{0,a}}=a \\,|\\, X_0=5)$, que l'on note ici $p^*$.\n",
    "\n",
    "Et, empiriquement, nous avons déterminé une estimation $\\widetilde{p}$ de $\\mathbb{P}(X_{\\tau_{0,a}}=a \\,|\\, X_0=5)$. Pour cela, on a simulé $M$ trajectoires que l'on note : $\\forall i \\in [ 1, M ], \\, X_\\tau^{(i)}$. Et on s'intéresse alors à :\n",
    "\\begin{equation*}\n",
    "    \\widetilde{p} = \\frac{\\# \\,\\left(\\text{trajectoires $i$ pour lesquelles } \\tau \\leq N \\text{ et } X_\\tau^{(i)} = a \\right)}{M}\n",
    "\\end{equation*}\n",
    "\n",
    "On peut alors réécrire $\\widetilde{p}$ tel que :\n",
    "\\begin{equation*}\n",
    "    \\widetilde{p} = \\frac{1}{M} \\sum_{i=1}^M \\mathbb{1}_{\\{X_\\tau^{(i)} = a \\}}\n",
    "\\end{equation*}\n",
    "\n",
    "On note pour simplifier : $\\forall i \\in [ 1, M ], \\, p_i \\triangleq \\mathbb{1}_{\\{X_\\tau^{(i)} = a \\}}$. Or, par définition de l'indicatrice, les $(p_i)_{1\\leq i \\leq M}$ suivent alors chacun une loi de Bernoulli de paramètre $p^*$ puisque :\n",
    "$$\n",
    "\\forall i \\in [ 1, M ], \\quad \\mathbb{E}[p_i] = \\mathbb{E}\\left[ \\mathbb{1}_{\\{X_\\tau^{(i)} = a \\}} \\right] = \\mathbb{P}\\left(X_\\tau^{(i)} = a \\right) = p^*.\n",
    "$$\n",
    "\n",
    "Et donc, \n",
    "$$\n",
    "\\forall i \\in [ 1, M ], \\quad p_i \\sim \\mathcal{B}(1,p^*) \\Longrightarrow \n",
    "\\begin{cases}\n",
    "\\mathbb{E}[p_i] = p^* < \\infty \\\\\n",
    "\\operatorname{Var}(p_i) = p^*(1- p^*) < \\infty\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Finalement, $ \\widetilde{p}$ est la moyenne empirique de $M$ variables i.i.d de Bernoulli (les $p_i$). Donc, d'après le \\textbf{Théorème Central Limite}, on a :\n",
    "\n",
    "$$\n",
    "\\boxed{\n",
    "\\sqrt{M}\\,\\frac{\\widetilde{p} - p^*}{\\sqrt{p^* (1 - p^*) } } \\,\n",
    "\\overset{\\mathcal{L}}{\\longrightarrow} \\,\\mathcal{N}(0,1)\n",
    "}\n",
    "$$\n",
    "\n",
    "Seulement, nous voulons déterminer un intervalle de confiance à 95\\% de notre estimation, pour ensuite vérifier si $p^*$ se trouve dans cet intervalle.\n",
    "\n",
    "Si on ne change rien, notre intervalle de confiance va dépendre de $p^*$, ce qui n'est pas du tout souhaitable. On va donc utiliser \\textbf{le théorème de Slutsky} pour se ramener à un intervalle de confiance indépendant de $p^*$.\n",
    "\n",
    "Premièrement, comme $p_1, p_2, \\dots, p_M$ sont des variables aléatoires i.i.d, \\textbf{la loi forte des grands nombres} nous assure que :\n",
    "$$\n",
    "\\widetilde{p} = \\frac{1}{M} \\sum_{i=1}^M p_i \\overset{p.s.}{\\longrightarrow} \\, \\mathbb{E}[p_1] = p^*\n",
    "$$\n",
    "\n",
    "Et donc, on a nécessairement le résultat plus faible suivant : \n",
    "$$ \n",
    "\\widetilde{p} \\overset{\\mathbb{P}}{\\longrightarrow} p^*\n",
    "$$\n",
    "\n",
    "Ainsi, en appliquant le théorème de continuité avec la fonction $x \\longmapsto \\frac{1}{\\sqrt{x(1 -x)} }$ sur $]0,1[$, on a :\n",
    "$$\n",
    "\\boxed{\n",
    "\\frac{1}{\\sqrt{\\widetilde{p} \\, (1 - \\widetilde{p}) }} \\overset{\\mathbb{P}}{\\longrightarrow} \\frac{1}{\\sqrt{ p^* (1 - p^*)}}\n",
    "}\n",
    "$$\n",
    "\\medskip\n",
    "\n",
    "Par conséquent, d'après le \\textbf{théorème de Slutsky}, on en déduit que :\n",
    "$$\n",
    "\\boxed{\n",
    "\\sqrt{M}\\,\\frac{\\widetilde{p} - p^*}{\\sqrt{\\widetilde{p}\\, (1 - \\widetilde{p} )} } \\,\n",
    "\\overset{\\mathcal{L}}{\\longrightarrow} \\,\\mathcal{N}(0,1)\n",
    "}\n",
    "$$\n",
    "\n",
    "On en déduit donc, en notant $u_\\alpha$ les quantiles d'ordre $\\alpha$ pour la loi $\\mathcal{N}(0,1)$, que :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{P}\\left( u_{\\frac{\\alpha}{2}} \\leq \\sqrt{M}\\,\\frac{\\widetilde{p} - p^*}{\\sqrt{\\widetilde{p}\\, (1 - \\widetilde{p}) } } \\leq u_{1 - \\frac{\\alpha}{2}} \\right) = 1 - \\alpha\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "    \\Longrightarrow  \\quad \\mathbb{P}\\left( \\sqrt{\\frac{\\widetilde{p}  \\,(1 - \\widetilde{p} )}{M}} u_{\\frac{\\alpha}{2}} \n",
    "    \\leq \\widetilde{p}  - p^* \n",
    "    \\leq \\sqrt{\\frac{\\widetilde{p} \\,(1 - \\widetilde{p} )}{M}} u_{1 - \\frac{\\alpha}{2}} \\right) = 1 - \\alpha\n",
    "\\end{equation*}\n",
    "\n",
    "Or, on cherche un intervalle de confiance à 95\\%. Et, on sait que pour $\\mathcal{N}(0,1)$, on a : $u_{0,975} \\approx 1,96$. On en déduit donc l'intervalle de confiance de notre estimation $\\widetilde{p}$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\operatorname{IC} = \\left[ \\widetilde{p} -1,96 \\,\\sqrt{\\frac{\\widetilde{p} \\, (1 - \\widetilde{p})}{M}} ; \\, \\widetilde{p} + 1,96 \\,\\sqrt{\\frac{\\widetilde{p} \\, (1 - \\widetilde{p})}{M}} \\, \\right]\n",
    "    }\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9XtYjQr3zZ4y",
    "outputId": "ca1b45f3-fe66-467a-a74b-36eccc6b4ccc"
   },
   "outputs": [],
   "source": [
    "print(\"Proba empirique =\",p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Cs-dV8Clzkbz"
   },
   "source": [
    "La valeur trouvée est très proche de la probabilité théorique qui est égale à $0.5$. On va pouvoir vérifier cela à l'aide d'un intervalle de confiance à 95% de notre estimation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KQxkbuUnztf5",
    "outputId": "ddc3c388-d6a1-4a83-e003-b54b33f098db"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-44f28239183b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mIC\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mp\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1.96\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1.96\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Intervalle de confiance =\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mIC\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'p' is not defined"
     ]
    }
   ],
   "source": [
    "IC = [p -1.96 * np.sqrt(p*(1 - p)/M), p + 1.96 * np.sqrt(p*(1 - p)/M)]\n",
    "print(\"Intervalle de confiance =\",IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BXHt31He0Hwz"
   },
   "source": [
    "Or, on a avait trouvé que $p^* = \\mathbb{P}(X_{\\tau_{0,a}}=a \\,|\\, X_0=5) = 0.5 $. Ainsi, on remarque effectivement que :\n",
    "$$\n",
    "\\boxed{\n",
    "p^* \\in \\operatorname{IC}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DE4BOdY9Wqf5"
   },
   "source": [
    "##### 1.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "To_66No3YnNR",
    "outputId": "ea87e2c2-ff25-44d3-a61c-35d184d95918"
   },
   "outputs": [],
   "source": [
    "moy = np.mean([L[i][0] for i in range (M)])\n",
    "print(\"moy =\",moy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7HxDpGdknJT_"
   },
   "source": [
    "On rappelle que le temps d'arrêt $\\tau_{0,a}$ est défini tel que:\n",
    "\\begin{equation*}\n",
    "    \\tau_{0,a} = \\min \\, \\{ n \\geqslant 0 \\; | \\; X_n = a \\text{ ou } X_n = 0 \\}\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "Le théorème énonce alors qu'en posant $\\forall i \\in [ 0, a ], \\; g(i) = \\mathbb{E}\\left[ \\tau_{0,a} \\,|\\, X_0 = i \\right]$, $(g(i))_{0 \\leq i \\leq a}$ est la plus petite solution positive du système suivant :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\begin{cases}\n",
    "        g(i) = 0 & \\text{si } i \\in \\{0,a\\} \\\\\n",
    "        g(i) = 1 + \\displaystyle\\sum_{j=1}^{a-1} p(i,j) \\, g(j) & \\text{sinon}\n",
    "    \\end{cases}\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "On peut alors écrire ce système sous forme matricielle, en notant $b = (1)_{0<i<a}$, $x=(g(i))_{0<i<a}$ et $M=(p(i,j))_{0<i,j<a}$ :\n",
    "\\begin{align*}\n",
    "    \\forall i \\in \\mathbb N,\\, 0 < i < a, \\quad &g(i) = 1 + \\sum_{j=1}^{a-1} p(i,j) \\, g(j) \\\\\n",
    "    \\Longrightarrow \\quad & x = b + Mx \\\\\n",
    "    \\Longrightarrow \\quad &\\boxed{\\left[I_{a-1}-M\\right]x = b}\n",
    "\\end{align*}\n",
    "\n",
    "On remarque, de la même manière d'après le \\textbf{lemme d'Hadamard}, la matrice $A = I_{a-1} - M$ est inversible, et on peut alors déterminer les différents valeurs des $g(i)$ dans le cadre de notre exemple qui est le jeu \"ruine du joueur\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ad_C_5n6oHe5",
    "outputId": "0ecd6343-bf63-4a62-cfe3-5422ad659a56"
   },
   "outputs": [],
   "source": [
    "def resolv_esperance(a,p) :\n",
    "  # Matrice M\n",
    "  M = np.zeros([a-1,a-1])\n",
    "  for i in range (a-2) :\n",
    "      M[i,i+1]=p\n",
    "      M[i+1,i]=1-p\n",
    "  A = np.eye(a-1) - M\n",
    "  # Vecteur b\n",
    "  b = np.array([1 for i in range(a-1)])\n",
    "  # Résolution\n",
    "  return np.linalg.solve(A, b)\n",
    "x = resolv_esperance(a,prob)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cO9rdKlUqeGl"
   },
   "source": [
    "On trouve alors : $\\mathbb{E}\\left[ \\tau_{0,a} \\,|\\, X_0 = 5 \\right] = 25 $."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TjfjdL-Oq9XD"
   },
   "source": [
    "De la même manière qu'à la question 1.a, nous venons de déterminer la \\textit{vraie} probabilité associée à $\\mathbb{E}\\left[ \\tau_{0,a} \\,|\\, X_0 = 5 \\right]$, que l'on note ici $\\theta^*$.\n",
    "\n",
    "Notre estimateur est ici une moyenne empirique :\n",
    "$$\n",
    "\\hat\\theta = \\overline{\\tau_{0,a}} = \\dfrac{1}{M}\\sum_{i=1}^M \\tau_{0,a}^{(i)}\n",
    "$$\n",
    "\n",
    "Donc, on a bien : $\\mathbb{E}[\\hat\\theta \\,|\\, X_0 = 5] \\underset{\\text{not.}}{=} \\mathbb{E}_5[\\hat\\theta] = \\mathbb{E}_5[\\tau_{0,a}^{(1)}] = 25$ en théorie (par identique distribution et linéarité de l'espérance).\n",
    "\n",
    "Il est nécessaire de trouver $\\operatorname{Var}_5[\\hat\\theta]$ pour pouvoir par la suite utiliser le Théorème Central Limite.\n",
    "\n",
    "Pour cela, on pose :\n",
    "$$\n",
    "\\widehat{S^2} = \\dfrac{1}{M-1} \\sum_{i=1}^M \\left( \\tau_{0,a}^{(i)} - \\overline{\\tau_{0,a}} \\right)^2\n",
    "$$\n",
    "\n",
    "Et il se trouve que $\\widehat{S^2}$ est un estimateur sans biais convergent vers $\\operatorname{Var}_5[\\hat\\theta]$.\n",
    "\n",
    "Ainsi, on peut alors appliquer le Théorème Central Limite :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\sqrt{M}\\, \\dfrac{\\hat\\theta - \\theta^*}{\\sqrt{\\widehat{S^2}}} \\, \\overset{\\mathcal{L}}{\\longrightarrow} \\, \\mathcal{N}(0,1)\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "On en déduit donc, en notant $u_\\alpha$ les quantiles d'ordre $\\alpha$ pour la loi $\\mathcal{N}(0,1)$, que :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\mathbb{P}\\left( u_{\\frac{\\alpha}{2}} \\leq \\sqrt{M}\\,\\dfrac{\\hat\\theta - \\theta^*}{\\sqrt{\\widehat{S^2}}} \\leq u_{1 - \\frac{\\alpha}{2}} \\right) = 1 - \\alpha\n",
    "\\end{equation*}\n",
    "\\begin{equation*}\n",
    "    \\Longrightarrow  \\quad \\mathbb{P}\\left( \\sqrt{\\frac{\\widehat{S^2}}{M}} u_{\\frac{\\alpha}{2}} \n",
    "    \\leq \\hat\\theta - \\theta^*\n",
    "    \\leq \\sqrt{\\frac{\\widehat{S^2}}{M}} u_{1 - \\frac{\\alpha}{2}} \\right) = 1 - \\alpha\n",
    "\\end{equation*}\n",
    "\n",
    "Or, on cherche un intervalle de confiance à 95\\%. Et, on sait que pour $\\mathcal{N}(0,1)$, on a : $u_{0,975} \\approx 1,96$. On en déduit donc l'intervalle de confiance de notre estimation $\\hat\\theta$ :\n",
    "\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\operatorname{IC} = \\left[ \\hat\\theta -1,96 \\,\\sqrt{\\frac{\\widehat{S^2}}{M}} ; \\, \\hat\\theta + 1,96 \\,\\sqrt{\\frac{\\widehat{S^2}}{M}} \\, \\right]\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "Et on peut donc le calculer grâce à Python. En premier lieu, on détermine la valeur de $\\widehat{S^2}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yPxTiVugAiwS",
    "outputId": "31664163-1201-4a31-ba41-fcd0cb9a4e5b"
   },
   "outputs": [],
   "source": [
    "S2 = (1/(M-1)) * np.sum([(L[i][0] - moy)**2 for i in range(M)])\n",
    "print(\"Variance empirique =\",S2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FjbZQZ4cCdbG"
   },
   "source": [
    "On peut alors déterminer notre intervalle de confiance $\\operatorname{IC}$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BUCtGZttCop2",
    "outputId": "fdf55fce-37df-405a-e8b0-b7b22c9e7ed6"
   },
   "outputs": [],
   "source": [
    "print(\"Espérance empirique =\",moy)\n",
    "\n",
    "IC = [moy - 1.96*np.sqrt(S2/M), moy + 1.96*np.sqrt(S2/M)]\n",
    "print(\"Intervalle de confiance à 95% =\",IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q6BOtGs_C88H"
   },
   "source": [
    "Or, on a avait trouvé que : $\\theta^* = \\mathbb{E}\\left[ \\tau_{0,a} \\,|\\, X_0 = 5 \\right] = 25 $. Ainsi, on remarque effectivement que :\n",
    "$$\n",
    "\\boxed{\n",
    "\\theta^* \\in \\operatorname{IC}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1_s9MBbuWzv4"
   },
   "source": [
    "##### 1.c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ROhc_g9TR-6M"
   },
   "source": [
    "On choisit arbitrairement $p=0.3 \\,(\\neq 0.5)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "id": "q6BBSlBAXRnW",
    "outputId": "72042c1c-5c1c-4d4d-b0ff-7cd77e037203"
   },
   "outputs": [],
   "source": [
    "prob = 0.3\n",
    "\n",
    "N = 100\n",
    "X0 = 5\n",
    "a = 10\n",
    "M = 1000\n",
    "\n",
    "fig = plt.figure(figsize=(8,3),dpi=200)\n",
    "\n",
    "L = []\n",
    "sum = 0\n",
    "for i in range (M) :\n",
    "  L.append(ruine_du_joueur(N, X0, a, prob, i<10))\n",
    "  sum+=(L[i][1]==a)\n",
    "plt.xlabel(\"Richesse\")\n",
    "plt.ylabel(\"Tour\")\n",
    "plt.title(\"Evolution de la richesse du joueur (p=\"+str(prob)+\")\")\n",
    "plt.show()\n",
    "p = sum / M\n",
    "print(\"Probabilité empirique =\",p)\n",
    "\n",
    "moy = np.mean([L[i][0] for i in range (M)])\n",
    "print(\"Moyenne empirique =\",moy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0TTgr-dTy_M"
   },
   "source": [
    "De la même manière qu'en 1.a, on peut obtenir les valeurs exactes des $\\mathbb{P}(X_{\\tau_{0,a}}=a|X_0=x)$ en résolvant un système linéaire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n3M5xGCuS5qT",
    "outputId": "a1153cbc-5310-428a-fe29-c87f6165ed9d"
   },
   "outputs": [],
   "source": [
    "x = resolv(a,prob)\n",
    "print(\"f( 0 ) =\",0)\n",
    "for i in range (1,a) :\n",
    "  print(\"f(\",i,\") =\",x[i-1])\n",
    "print(\"f( a ) =\",1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sGqzsVloQ302",
    "outputId": "88150f3c-4805-4cfd-a259-99e1db57ebda"
   },
   "outputs": [],
   "source": [
    "print(\"Probabilité empirique =\",p)\n",
    "print(\"La vraie probabilité vaut :\",np.round(x[4],5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhlT5GkcGsbs"
   },
   "source": [
    "On peut aussi déterminer la vraie valeur de la moyenne des temps $\\mathbb{E}[\\tau_{0,a} \\,|\\, X_0 = x]$ pour tout $x \\in \\{1,\\dots, 10\\}$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yzH61_vsHAuy",
    "outputId": "14d174ad-ea89-4f34-a496-2aa9f1517651"
   },
   "outputs": [],
   "source": [
    "e = resolv_esperance(a,prob)\n",
    "print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2TLZ5QGXRc50",
    "outputId": "31351d00-8324-4b11-f7b6-b5899c952b39"
   },
   "outputs": [],
   "source": [
    "print(\"Moyenne empirique =\",moy)\n",
    "print(\"La vraie moyenne de temps d'atteinte vaut :\",e[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWeHR3AdboSY"
   },
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5_hjNoCQ5qAJ"
   },
   "source": [
    "Dans un premier temps, on va construire aléatoirement la matrice stochastique $P$ qui régira les déplacements des élèves et du monstre dans les 10 zones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XkPW-K9ibvuS",
    "outputId": "7bbdedb8-aba3-40b7-f020-21222547654e"
   },
   "outputs": [],
   "source": [
    "def matrice_stochastique(n, m):\n",
    "  # On crée une matrice aléatoire de taille n x m\n",
    "  P = np.random.rand(n, m)\n",
    "  # On divise chaque coefficient de P par la somme des coefficients de sa ligne \n",
    "  P /= np.sum(P, axis=1, keepdims=True)\n",
    "  return P\n",
    "\n",
    "P = matrice_stochastique(10,10)\n",
    "print(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BCsLzjFkcHTP"
   },
   "source": [
    "###### 2.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xcs2cSxBcbgi",
    "outputId": "71454fe6-bb52-461c-f001-05898363bf66"
   },
   "outputs": [],
   "source": [
    "N = 10000\n",
    "\n",
    "def simulation_etudiant_compteur_zone(P, X0, N):\n",
    "  # Initialisation\n",
    "  Xn = X0 #zone actuelle\n",
    "  L_zone = [0 for i in range (10)] #compteur de passages dans une zone\n",
    "  L_zone[X0-1]+=1\n",
    "  # Tours\n",
    "  for i in range(N):\n",
    "    Xn = sim_dis(P[Xn-1], range(1,11), 1)[0] #déplacement de l'élève\n",
    "    L_zone[Xn-1]+=1\n",
    "  return L_zone\n",
    "\n",
    "L_zone = simulation_etudiant_compteur_zone(P, 1, N)\n",
    "p_zone = [L_zone[i]/N for i in range (10)]\n",
    "print(\"Fraction de temps passée par l'étudiant dans chaque zone :\",p_zone)\n",
    "\n",
    "ecart = np.dot(p_zone,P) - p_zone\n",
    "erreur = 0\n",
    "for i in range (10) :\n",
    "  erreur += abs(ecart[i])\n",
    "print(\"Valeur de l'erreur =\",erreur)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EgVPDc89VPJj"
   },
   "source": [
    "Soit $\\pi = (\\pi_i)_{1 \\leq i \\leq 10}$ la solution de l'équation $\\pi^\\top P = \\pi^\\top$ avec $\\pi_i \\in [0, 1]$ et $\\sum_{i=1}^n \\pi_i = 1$. Un tel vecteur s'appelle une probabilité invariante pour $P$.\n",
    "\n",
    "Or,\n",
    "\\begin{align*}\n",
    "    \\pi^\\top P = \\pi^\\top \\quad \\Longleftrightarrow& \\quad (\\pi^\\top P)^\\top = (\\pi^\\top)^\\top \\\\\n",
    "    \\Longleftrightarrow& \\quad P^\\top \\pi = \\pi \\\\\n",
    "    \\Longleftrightarrow& \\quad \\pi \\text{ est un vecteur propre associé à la valeur propre 1 de } P^\\top\n",
    "\\end{align*}\n",
    "\n",
    "Et le fait que $\\pi_i \\in [0, 1]$ et $\\sum_{i=1}^n \\pi_i = 1$ nous permet de conclure que $\\pi$ est \\textbf{le vecteur propre stochastique} de la matrice $P^\\top$ associé à la valeur propre 1.\n",
    "\n",
    "\\\\\n",
    "\n",
    "À partir de maintenant, on note $A = P^\\top$, avec $P$ notre matrice stochastique à coefficients strictement positifs. Montrons pour commencer ce premier résultat :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\text{1 est valeur propre de $P$ et toute valeur propre complexe $\\lambda$ de $P$ vérifie $|\\lambda| \\leq 1$.}\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "\\\\\n",
    "\n",
    "En effet, soit $U = (1)_{1 \\leq i \\leq 10}$. Alors, comme $P$ est une matrice stochastique, on sait que : $\\sum_{j=1}^{10} p_{i,j} = 1$, ce qui équivaut à dire que : $PU = U$.\n",
    "\n",
    "Cela prouve que 1 est bien valeur propre de $P$, et $U$ est un vecteur propre associé. À noter que 1 est donc aussi valeur propre de $A = P^\\top$. \\\\\n",
    "\n",
    "Soit $\\lambda \\in \\operatorname{Sp}(P)$, et soit $X = (x_i)_{1 \\leq i \\leq 10}$ un vecteur propre associé. Soit $i \\in [1, 10]$ tel que $|x_i| = \\max_{1\\leq k \\leq 10} |x_k|$. Comme par définition $PX = \\lambda X$, en regardant la $i$-ième coordonnée, on obtient :\n",
    "\\begin{equation*}\n",
    "    p_{i,1} \\, x_1 + \\dots + p_{i,10} \\,  x_{10} = \\lambda x_i\n",
    "\\end{equation*}\n",
    "\n",
    "En passant au module, on obtient donc que :\n",
    "\\begin{equation*}\n",
    "    |\\lambda x_i| = |\\lambda| |x_i| =  |p_{i,1} \\,x_1 + \\dots + p_{i,10}\\, x_{10}| \\leq ( p_{i,1} + \\dots + p_{i,10}) |x_i| = |x_i|\n",
    "\\end{equation*}\n",
    "\n",
    "On en conclut donc que : $|\\lambda | \\leq 1$. \n",
    "\n",
    "\\\\\n",
    "\n",
    "Il est alors temps d'utiliser \\textbf{le théorème de Perron-Frobenius}. Bien qu'ici, le théorème de Perron nous suffira.\n",
    "\n",
    "À noter que l'écriture la plus connue de ce théorème concerne les matrices réelles primitives, mais on s'intéressera ici uniquement aux matrices réelles strictement positives (pour simplifier un peu).\n",
    "\n",
    "> Soit $A$ une matrice réelle strictement positive. Son rayon spectral $\\rho(A)$ est une valeur propre simple et dominante (i.e. de module strictement supérieur à celui des autres valeurs propres). Elle admet un vecteur propre strictement positif. [[source](https://agreg-maths.univ-rennes1.fr/documentation/docs/agreg-Sto.pdf)]\n",
    "\n",
    "\n",
    "Or, dans notre cas, on vient de montrer que : $\\forall \\lambda \\in \\operatorname{Sp}(P), \\; |\\lambda| \\leq 1$, et que 1 est bien valeur propre de $P$. Donc,\n",
    "\\begin{equation*}\n",
    "    \\rho(P) = 1 \\quad \\Longrightarrow \\quad \\rho(A) = 1\n",
    "\\end{equation*}\n",
    "\n",
    "Donc, d'après le théorème de Perron appliqué à la matrice $A$, 1 est une valeur propre \\textbf{simple} et dominante de $A$. Mais on en déduit aussi que $A$ \\textbf{admet un vecteur propre $v$ strictement positif}.\n",
    "\n",
    "Et, comme l'espace propre associé à la valeur propre 1 est de dimension 1 (d'après le théorème de Perron), il est engendré par le vecteur $v > 0$. Donc, en le normalisant, c'est-à-dire en posant $\\pi$ tel que :\n",
    "\\begin{equation*}\n",
    "    \\pi = \\dfrac{v}{\\left\\lVert v \\right\\rVert}\n",
    "\\end{equation*}\n",
    "\n",
    "On vient donc de prouver que :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\text{$P$ admet une unique probabilité invariante $\\pi$ (avec $\\pi > 0$) }\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "\\\\\n",
    "\n",
    "Il est également possible de déterminer explicitement une approximation de ce vecteur $\\pi$ à epsilon près à l'aide de \\textbf{la méthode de la puissance itérée}. \n",
    "\n",
    "En effet, comme la valeur propre 1 est dominante, c'est-à-dire que :\n",
    "\\begin{equation*}\n",
    "     \\forall \\lambda \\in \\operatorname{Sp}(A)\\backslash \\{1\\}, \\quad |\\lambda| < 1\n",
    "\\end{equation*}\n",
    "\n",
    "on peut appliquer le théorème correspondant à la méthode de la puissance itérée qui s'écrit comme suit :\n",
    "\n",
    "> On définit la suite $(v_k)_{k \\in \\mathbb N}$ telle que :\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "        v_0 \\text{ choisi arbitrairement dans } \\mathbb{R}^{10} &\\\\\n",
    "        \\forall k \\in \\mathbb N, \\quad v_{k+1} = \\dfrac{A\\, v_k}{\\left\\lVert A\\, v_k\\right\\rVert} &\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "> La valeur propre dominante est 1, donc le théorème peut alors s'écrire de cette manière :\n",
    "- \\textbf{Si} $v_0$ n'appartient pas au sous-espace engendré par les vecteurs propres associés aux autres valeurs propres, avec $\\left\\lVert v_0\\right\\rVert = 1$,\n",
    "- \\textbf{Alors} $v_k \\underset{k \\rightarrow + \\infty}{\\longrightarrow} \\pi$\n",
    "\n",
    "[[source](https://fr.wikipedia.org/wiki/Méthode_de_la_puissance_itérée)]\n",
    "\n",
    "\n",
    "Dans la vraie version du théorème, on aurait :\n",
    "\\begin{equation*}\n",
    "    v_k \\underset{k \\rightarrow + \\infty}{\\longrightarrow} v \\quad \\text{ où $v$ est un vecteur unitaire de $A$ associé à la valeur propre 1}\n",
    "\\end{equation*}\n",
    "\n",
    "Mais cela se ramène bien ici à $v_k \\underset{k \\rightarrow + \\infty}{\\longrightarrow} \\pi$ puisque, par \\textbf{unicité} de $\\pi$, si $v$ est un vecteur propre associé à la valeur propre 1 tel que $v>0$ et $\\left\\lVert v \\right\\rVert = 1$, alors $\\boxed{v= \\pi}$. \\\\\n",
    "\n",
    "\\\\\n",
    "\n",
    "Pour ce qui est de la preuve de ce théorème, voici quelques liens qui permettent d'y voir plus clair :\n",
    "\n",
    "- Une preuve sympathique de la méthode de la puissance itérée : https://moodle.utc.fr/file.php/665/MT09-ch8.pdf\n",
    "- Les corollaires 2.8 et 2.10 permettent de mieux comprendre le pourquoi de l'utilisation de cette méthode dans le cadre des matrices stochastiques aux coefficients strictements positifs : https://www.imo.universite-paris-saclay.fr/~daniel.perrin/CAPES/algebre/Markov1.pdf\n",
    "\n",
    "\\\\\n",
    "\n",
    "Voici alors l'implémentation de cette méthode algorithmique sur notre matrice $A = P^\\top$ :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x0o4uc3SP-cq",
    "outputId": "255d109e-3d33-42d2-bd6b-c6f25c522541"
   },
   "outputs": [],
   "source": [
    "def methode_puissance_iteree(A, epsilon=1e-8, max_iterations=1000):\n",
    "    n = A.shape[0]\n",
    "    v = np.ones(n) / n  # Choix arbitraire pour v_0 de norme 1\n",
    "\n",
    "    for i in range(max_iterations):\n",
    "        v_new = np.dot(A.T, v)  # On s'intéresse à la transposée de la matrice dans notre cas\n",
    "        v_new = v_new / np.linalg.norm(v_new, ord=1)  # On normalise le nouveau vecteur v\n",
    "\n",
    "        if np.linalg.norm(v_new - v, ord=1) < epsilon: # On répète l'opération jusqu'à se situer assez proche de vecteur v limite\n",
    "            break\n",
    "\n",
    "        v = v_new\n",
    "\n",
    "    # Juste un test final pour vérifier la convergence de la suite v_k vers le vecteur propre v pour la matrice A^T\n",
    "    eig_val = np.dot(A.T, v) / v\n",
    "    if np.allclose(eig_val, 1):\n",
    "        return v\n",
    "    else:\n",
    "        raise ValueError(\"La suite v_k ne converge pas vers un vecteur propre v\")\n",
    "\n",
    "pi = methode_puissance_iteree(P)\n",
    "print(pi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iCyxv0pTP-0D"
   },
   "source": [
    "Notre vecteur $\\pi$ déterminé empiriquement ($p_{zone}$) est alors très proche de la valeur théorique attendue déterminée par la méthode de la puissance itérée. Et cela se vérifie d'autant plus que $N$ est grand.\n",
    "\n",
    "\\\\\n",
    "\n",
    "Nous nous sommes alors intéressés à étudier la différence (l'erreur) entre $p_{zone}\\times P$ et notre vecteur empirique $p_{zone}$. Et\n",
    "effectivement, on peut remarquer que cette erreur tend vers $0$ lorque $N$ (le nombre de tours de jeu) tend vers l'infini :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "6PC7BF_YVGrj",
    "outputId": "f66156a0-2d31-4c9e-da7c-596e1d740221"
   },
   "outputs": [],
   "source": [
    "def calcul_erreur_1(P, X0, i_max) :\n",
    "  L_erreur = []\n",
    "  L_N = [i*100 for i in range (1,i_max)]\n",
    "  for N in L_N :\n",
    "    L_zone = simulation_etudiant_compteur_zone(P, 1, N)\n",
    "    p_zone = [L_zone[i]/N for i in range (10)]\n",
    "\n",
    "    ecart = np.dot(p_zone,P) - p_zone\n",
    "    erreur = 0\n",
    "    for i in range (10) :\n",
    "      erreur += abs(ecart[i])\n",
    "    L_erreur.append(erreur)\n",
    "  plt.plot(L_N,L_erreur)\n",
    "  plt.xlabel(\"Nombre de tours\")\n",
    "  plt.ylabel(\"Erreur\")\n",
    "  plt.title(\"Evolution de l'erreur en fonction du nombre de tours de jeu\")\n",
    "  plt.show()\n",
    "\n",
    "calcul_erreur_1(P, 1, 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4g5UZ465QTd_"
   },
   "source": [
    "On peut donc constater que le vecteur $\\pi$, probabilité empirique de $P$, peut être approchée par la limite des $p_{zone,N}$ lorsque $N$ tend vers l'infini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ay3KMlFecORE"
   },
   "source": [
    "##### 2.b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gRQfKsSqyrHW"
   },
   "source": [
    "On pose maintenant $X_0=5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_0z9uyN6gE0i",
    "outputId": "77952b89-8eba-4210-8441-bb4747cb4a2b"
   },
   "outputs": [],
   "source": [
    "L_zone = simulation_etudiant_compteur_zone(P, 5, N)\n",
    "P_zone = [L_zone[i]/N for i in range (10)]\n",
    "print(P_zone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5wXTh6u6wicl"
   },
   "source": [
    "La nouvelle valeur de $p_{zone}$ est très similaire à celle trouvée lorsque $X_0$ valait $1$. En effet, lorsque l'on avance dans les tours de jeu, l'influence de la case de départ deviens de plus en plus faible. On peut vérifier cela en comparant l'écart entre des deux vecteurs en fonction de $N$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 472
    },
    "id": "eA7U5IsPyF9j",
    "outputId": "c513c55a-94e0-4ec4-fa0a-c31df56c5b66"
   },
   "outputs": [],
   "source": [
    "def calcul_erreur_2(P, i_max) :\n",
    "  L_erreur = []\n",
    "  L_N = [i*100 for i in range (1,i_max)]\n",
    "  for N in L_N :\n",
    "    L_zone_1 = simulation_etudiant_compteur_zone(P, 1, N)\n",
    "    p_zone_1 = [L_zone_1[i]/N for i in range (10)]\n",
    "    L_zone_2 = simulation_etudiant_compteur_zone(P, 5, N)\n",
    "    p_zone_2 = [L_zone_2[i]/N for i in range (10)]\n",
    "\n",
    "    ecart = [p_zone_1[i] - p_zone_2[i] for i in range (10)]\n",
    "    erreur = 0\n",
    "    for i in range (10) :\n",
    "      erreur += abs(ecart[i])\n",
    "    L_erreur.append(erreur)\n",
    "  plt.plot(L_N,L_erreur)\n",
    "  plt.xlabel(\"Nombre de tours\")\n",
    "  plt.ylabel(\"Erreur\")\n",
    "  plt.title(\"Evolution de l'erreur en fonction du nombre de tours de jeu\")\n",
    "  plt.show()\n",
    "\n",
    "calcul_erreur_2(P, 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b9L9GUFD0WaJ"
   },
   "source": [
    "Du fait de la case de départ qui importe peu lorsque le nombre de tours de jeu $N$ augmente, on tire les mêmes conclusions que pour la 2.a., c'est-à-dire que : \n",
    "\n",
    "On peut donc constater que le vecteur $\\pi$, probabilité empirique de $P$, peut être approchée par la limite des $p_{zone,N}$ lorsque $N$ tend vers l'infini."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QxGNyMNWcSXi"
   },
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VL3s5S_rga5q",
    "outputId": "aadf6b39-6f7f-4938-9a33-698577c50ba1"
   },
   "outputs": [],
   "source": [
    "M = 100000\n",
    "N = 1000\n",
    "X0_eleve = 1\n",
    "X0_monstre = 10\n",
    "\n",
    "def simulation_etudiant_survie_statique(P, X0_eleve, X0_monstre, N):\n",
    "  # Si l'élève et le monstre sont déjà sur la même case (rip)\n",
    "  if X0_eleve==X0_monstre :\n",
    "    return 0\n",
    "  # Initialisation\n",
    "  Xn = X0_eleve #zone actuelle de l'étudiant\n",
    "  # Tours\n",
    "  for i in range(N):\n",
    "    Xn = sim_dis(P[Xn-1], range(1,11), 1)[0] #déplacement de l'élève\n",
    "    if Xn==X0_monstre : #si l'élève et le monstre sont sur la même case (rip)\n",
    "      return (i+1)\n",
    "  return N #l'élève a survécu toute la partie (pendant N tours)\n",
    "\n",
    "L_tps_survie = [simulation_etudiant_survie_statique(P, X0_eleve, X0_monstre, N) for _ in range (M)]\n",
    "moy = np.mean(L_tps_survie)\n",
    "print(\"Temps de survie moyen =\",moy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OL5qCYqdy1bM"
   },
   "source": [
    "Soit $(X_n)_{n \\in \\mathbb N}$ la chaîne de Markov associé à l'étudiant. Le monstre reste ici immobile dans une zone précise noté $a$.\n",
    "\n",
    "On note ici :\n",
    "\\begin{equation*}\n",
    "    \\tau_{0,a} = \\min \\, \\{ n \\geqslant 0 \\; | \\; X_n = a \\}\n",
    "\\end{equation*}\n",
    "\n",
    "L'objectif ici est de calculer le temps de survie moyen exact de l'étudiant. C'est-à-dire le nombre de tour où l'étudiant n'atteint pas la zone $a$. Par conséquent, à l'image de la question 1.b, on s'intéresse ici au temps d'atteinte moyen de la zone $a$ pour la chaîne de Markov $(X_n)$.\n",
    "\n",
    "Ainsi, on cherche ici à calculer : \n",
    "$$\n",
    "\\forall i \\in [ 1, a ], \\quad \\mathbb{E}_i[\\tau_a] = \\mathbb{E}\\left[ \\tau_a \\,|\\, X_0 = i \\right]\n",
    "$$\n",
    "\n",
    "D'après le théorème sur le temps moyen d'atteinte, on peut alors énoncer que $(\\mathbb{E}_i[\\tau_a])_{1\\leq i \\leq a}$ est la plus petite solution positive du système suivant :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\begin{cases}\n",
    "        y_i = 0 & \\text{si } i = a \\\\\n",
    "        y_i = 1 + \\displaystyle\\sum_{j=1}^{a-1} p(i,j) \\, y_j & \\text{sinon}\n",
    "    \\end{cases}\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "On peut alors écrire ce système sous forme matricielle, en notant $b = (1)_{0<i<a}$, $x=(\\mathbb{E}_i[\\tau_a])_{0<i<a}$ et $P'=(p(i,j))_{0<i,j<a}$ matrice extraite de $P$ :\n",
    "\\begin{align*}\n",
    "    \\forall i \\in \\mathbb N,\\, 0 < i < a, \\quad &\\mathbb{E}_i[\\tau_a] = 1 + \\sum_{j=1}^{a-1} p(i,j) \\, \\mathbb{E}_j[\\tau_a] \\\\\n",
    "    \\Longrightarrow \\quad & x = b + P'x \\\\\n",
    "    \\Longrightarrow \\quad &\\boxed{\\left[I_{a-1}-P'\\right]x = b}\n",
    "\\end{align*}\n",
    "\n",
    "On remarque, de la même manière d'après le \\textbf{lemme d'Hadamard}, que la matrice $A = I_{a-1} - P'$ est inversible, et on peut alors déterminer les différents valeurs des $\\mathbb{E}_i[\\tau_a]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Vln39F5IzXH8",
    "outputId": "eedd7f05-bf25-4203-cb6e-afb0fe37461c"
   },
   "outputs": [],
   "source": [
    "def resolv_Q3(a,P) :\n",
    "  # Matrice A\n",
    "  A = np.eye(a-1) - np.array(P[:a-1,:a-1])\n",
    "  # Vecteur b\n",
    "  b = np.array([1 for i in range(a-1)])\n",
    "  # Résolution\n",
    "  return np.linalg.solve(A, b)\n",
    "\n",
    "X0_monstre = 10\n",
    "x = resolv_Q3(X0_monstre,P)\n",
    "x = np.append(x,0) # Partir de la zone 10 revient à partir dans la zone du monstre, donc le temps de survie moyen exact de l'étudiant vaut 0.\n",
    "print(\"Toutes les solutions pour les zones de départ variant de 1 à 10 :\",x)\n",
    "print(\"\")\n",
    "print(\"Temps de survie moyen exact de l'étudiant partant de la zone 1 =\",np.round(x[0],3))\n",
    "print(\"Temps de survie moyen empirique =\", moy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Pb2MhQLy37ej"
   },
   "source": [
    "La valeur qu'on trouve pour $\\mathbb{E}\\left[ \\tau_a \\,|\\, X_0 = 1 \\right]$ est vraiment similaire à celle trouvée empiriquement par une méthode de Monte Carlo (et ce d'autant plus lorsque $M$ est grand). \n",
    "\n",
    "Et cela peut par exemple se vérifier à l'aide d'un intervalle de confiance.\n",
    "\n",
    "En effet, en suivant la méthode de la question 1.b, on peut alors déterminer un intervalle de confiance à 95\\% notre estimation de Monte-Carlo, pour pouvoir comparer notre estimateur à la vraie valeur de $\\mathbb{E}_1[\\tau_a]$.\n",
    "\n",
    "En notant $\\hat\\theta$ notre estimateur, et $\\widehat{S^2}$ l'estimateur sans biais de la variance, on en déduit que l'intervalle de confiance correspondant est alors :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\operatorname{IC} = \\left[ \\hat\\theta -1,96 \\,\\sqrt{\\frac{\\widehat{S^2}}{M}} ; \\, \\hat\\theta + 1,96 \\,\\sqrt{\\frac{\\widehat{S^2}}{M}} \\, \\right]\n",
    "    }\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_wuqPUW3YNN2",
    "outputId": "5b9ca3b1-6c07-41c0-b0a8-7c8f68ad0660"
   },
   "outputs": [],
   "source": [
    "print(\"Espérance empirique =\",moy)\n",
    "print(\"Vraie espérance =\",np.round(x[0],3))\n",
    "\n",
    "S2 = (1/(M-1)) * np.sum([(L_tps_survie[i] - moy)**2 for i in range(M)])\n",
    "IC = [moy - 1.96*np.sqrt(S2/M), moy + 1.96*np.sqrt(S2/M)]\n",
    "print(\"Intervalle de confiance à 95% =\",IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m1UgWddNYyiE"
   },
   "source": [
    "Ainsi, en notant $\\theta^* = \\mathbb{E}\\left[ \\tau_a \\,|\\, X_0 = 1 \\right]$, on remarque effectivement que :\n",
    "$$\n",
    "\\boxed{\n",
    "\\theta^* \\in \\operatorname{IC}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "prrzzBoqcWHJ"
   },
   "source": [
    "### Question 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ONioXMFviqv3",
    "outputId": "4c3358d6-2730-48dd-b924-a38e07bc7a94"
   },
   "outputs": [],
   "source": [
    "M = 100000\n",
    "N = 10000\n",
    "X0_eleve = 1\n",
    "X0_monstre = 10\n",
    "\n",
    "def simulation_etudiant_survie_mobile(P, X0_eleve, X0_monstre, N):\n",
    "  # Si l'élève et le monstre sont déjà sur la même case (rip)\n",
    "  if X0_eleve==X0_monstre :\n",
    "    return 0\n",
    "  # Initialisation\n",
    "  Xn_eleve = X0_eleve #zone actuelle de l'étudiant\n",
    "  Xn_monstre = X0_monstre #zone actuelle du monstre\n",
    "  # Tours\n",
    "  for i in range(N):\n",
    "    Xn_eleve = sim_dis(P[Xn_eleve-1], range(1,11), 1)[0] #déplacement de l'élève\n",
    "    Xn_monstre = sim_dis(P[Xn_monstre-1], range(1,11), 1)[0] #déplacement du monstre\n",
    "    if Xn_eleve==Xn_monstre : #si l'élève et le monstre sont sur la même case (rip)\n",
    "      return i+1\n",
    "  return N+1 #l'élève a survécu toute la partie (pendant N tours)\n",
    "\n",
    "L_tps_survie = [simulation_etudiant_survie_mobile(P, X0_eleve, X0_monstre, N) for i in range (M)]\n",
    "moy = np.mean(L_tps_survie)\n",
    "print(\"Temps de survie moyen =\",moy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XNltAbJzFR_F"
   },
   "source": [
    "Soient les chaînes de Markov $(X_{k,\\text{monstre}})$ et $(X_{k,\\text{élève}})$ traduisant le déplacement de l'élève et du monstre sur les 10 zones en fonction du temps. Ces déplacements sont régis par la matrice stochastique $P$. La suite des $X_k=(X_{k,\\text{monstre}}, X_{k,\\text{élève}})$ forme elle-même une chaîne de Markov. \\\\\n",
    "\n",
    "Soit le temps d'arrêt $\\tau$ défini par :\n",
    "$$\n",
    "\\tau = \\min \\, \\{ k \\geqslant 0 \\; | \\; X_{k,\\text{monstre}}=X_{k,\\text{élève}} \\}\n",
    "$$\n",
    "\n",
    "On cherche ici à calculer : \n",
    "$$\n",
    "\\forall i,j \\in [|1, 10|], \\quad \\mathbb{E}_{(i,j)}[\\tau] = \\mathbb{E}\\left[ \\tau \\,|\\, X_0 = (i,j) \\right]\n",
    "$$\n",
    "\n",
    "D'après le théorème sur le temps moyen d'atteinte (cf. annexe), on peut alors énoncer que $(\\mathbb{E}_{(i,j)}[\\tau])_{1\\leq i,j \\leq 10}$ est la plus petite solution positive du système suivant :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\begin{cases}\n",
    "        y_{(i,j)} = 0 & \\text{si } i = j \\\\\n",
    "        y_{(i,j)} = 1 + \\displaystyle\\sum_{k\\ne{l}} p((i,j),(k,l)) \\, y_{(k,l)} & \\text{sinon}\n",
    "    \\end{cases}\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "On peut alors écrire ce système sous forme matricielle, en notant $b = (1)_{1\\le{n}\\le90}$, $x=(\\mathbb{E}_{(i,j)}[\\tau])_{i\\ne{j}}$ et $P'=(p((i,j),(k,l)))_{i\\ne{j},k\\ne{l}}$ matrice extraite de $P$ :\n",
    "\\begin{align*}\n",
    "    \\forall (i,j) \\in \\mathbb N^2,\\, 1 \\le i,j \\le 10, i \\ne j, \\quad &\\mathbb{E}_{(i,j)}[\\tau] = 1 + \\sum_{k\\ne{l}} p((i,j),(k,l)) \\, \\mathbb{E}_{(k,l)}[\\tau] \\\\\n",
    "    \\Longrightarrow \\quad & x = b + P'x \\\\\n",
    "    \\Longrightarrow \\quad &\\boxed{\\left[I_{90}-P'\\right]x = b}\n",
    "\\end{align*}\n",
    "\n",
    "On remarque, de la même manière d'après le \\textbf{lemme d'Hadamard}, que la matrice $A = I_{90} - P'$ est inversible, et on peut alors déterminer les différents valeurs des $\\mathbb{E}_{(i,j)}[\\tau]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hPF8Cgwo7fh1",
    "outputId": "2482d0de-1e25-4dc2-ff6f-0869bf508281"
   },
   "outputs": [],
   "source": [
    "def matrice_stochastique_couple(P):\n",
    "  taille = len(P[0][:])\n",
    "  PP = np.zeros([taille**2,taille**2])\n",
    "  for i in range (taille): #Dizaines : zone du monstre avant le tour\n",
    "    for j in range (taille): #Unités : zone de l'élève avant le tour\n",
    "      for k in range (taille): #Dizaines : zone du monstre après le tour\n",
    "        for l in range (taille): #Unités : zone de l'élève après le tour\n",
    "          PP[10*k+l,10*i+j] = P[k,i] * P[l,j]\n",
    "  return PP\n",
    "\n",
    "def remove_line_column(P,l,k):\n",
    "  PP1 = np.array(P[:l,:k])\n",
    "  PP2 = np.array(P[l+1:,:k])\n",
    "  PP3 = np.array(P[:l,k+1:])\n",
    "  PP4 = np.array(P[l+1:,k+1:])\n",
    "  PPP1 = np.vstack((PP1, PP2))\n",
    "  PPP2 = np.vstack((PP3, PP4))\n",
    "  PPP = np.hstack((PPP1, PPP2))\n",
    "  return PPP\n",
    "\n",
    "def resolv_Q4(P):\n",
    "  # Matrice A\n",
    "  PP = matrice_stochastique_couple(P)\n",
    "  for i in range (10): \n",
    "    PP = remove_line_column(PP,10*i,10*i)\n",
    "  A = np.eye(90) - PP\n",
    "  # Vecteur b\n",
    "  b = np.array([1 for i in range(90)])\n",
    "  # Résolution\n",
    "  return np.linalg.solve(A, b)\n",
    "\n",
    "x = resolv_Q4(P)\n",
    "xx = []\n",
    "i=0\n",
    "for E in x:\n",
    "  if (i%10)==0:\n",
    "    xx.append(0)\n",
    "  xx.append(E)\n",
    "  i+=1\n",
    "if (i%10)==0:\n",
    "  xx.append(0)\n",
    "Solution = np.zeros([10,10])\n",
    "for i in range (10):\n",
    "  for j in range (10):\n",
    "    Solution[i,j] = xx[i+10*j]\n",
    "\n",
    "print(\"Toutes les solutions pour les zones de départ variant de 1 à 10 :\",x)\n",
    "print(\"\")\n",
    "print(\"Temps de survie moyen exact de l'étudiant partant de la zone 1 avec le monstre partant de la zone 10 =\", np.round(Solution[9,0],3))\n",
    "print(\"Temps de survie moyen empirique =\", moy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l_ih63qJiB6i"
   },
   "source": [
    "Encore une fois, la valeur qu'on trouve pour $\\mathbb{E}\\left[ \\tau_a \\,|\\, X_{0,élève} = 1 , X_{0,monstre} = 10\\right]$ est vraiment similaire à celle trouvée empiriquement par une méthode de Monte Carlo (et ce d'autant plus lorsque $M$ est grand).\n",
    "\n",
    "Et cela peut notamment se vérifier à l'aide d'un intervalle de confiance par exemple.\n",
    "\n",
    "En effet, en suivant la méthode de la question 1.b, on peut alors déterminer un intervalle de confiance à 95\\% notre estimation de Monte-Carlo, pour pouvoir comparer notre estimateur à la vraie valeur de $\\mathbb{E}_{(10,1)}[\\tau]$.\n",
    "\n",
    "En notant $\\hat\\theta$ notre estimateur, et $\\widehat{S^2}$ l'estimateur sans biais de la variance, on en déduit que l'intervalle de confiance correspondant est alors :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\operatorname{IC} = \\left[ \\hat\\theta -1,96 \\,\\sqrt{\\frac{\\widehat{S^2}}{M}} ; \\, \\hat\\theta + 1,96 \\,\\sqrt{\\frac{\\widehat{S^2}}{M}} \\, \\right]\n",
    "    }\n",
    "\\end{equation*}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KNv3iZ4dZmjk",
    "outputId": "35f01dca-f362-468c-e2e3-0fb4965e00ce"
   },
   "outputs": [],
   "source": [
    "print(\"Espérance empirique =\",moy)\n",
    "print(\"Vraie espérance =\",np.round(Solution[0,9],3))\n",
    "\n",
    "S2 = (1/(M-1)) * np.sum([(L_tps_survie[i] - moy)**2 for i in range(M)])\n",
    "IC = [moy - 1.96*np.sqrt(S2/M), moy + 1.96*np.sqrt(S2/M)]\n",
    "print(\"Intervalle de confiance à 95% =\",IC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p22eoHwkahqA"
   },
   "source": [
    "Ainsi, en notant $\\theta^* = \\mathbb{E}\\left[ \\tau_a \\,|\\, X_{0,élève} = 1 , X_{0,monstre} = 10\\right]$, on remarque effectivement que :\n",
    "$$\n",
    "\\boxed{\n",
    "\\theta^* \\in \\operatorname{IC}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fL8aPwVbcVue"
   },
   "source": [
    "### Question 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yfo2JRm6Idwu"
   },
   "source": [
    "Dans cette question, on réalise la même expérience que précedemment, mais en consiférent plusieurs étudiants en même temps. Tous commencent sur la zone $1$, le monstre commence sur la zone $10$. Tous les individus sont soumis à la même matrice de probabilité $P$. On arrête l'expérience lorsque le premier étudiant est mangé par le monstre mobile, et on étudiera le temps moyen avant le premier mort en fonction du nombre d'étudiants au départ.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 473
    },
    "id": "c1v7UHDuJrjy",
    "outputId": "8c4859b8-d2e8-44df-bfe7-1ff8c4ef293b"
   },
   "outputs": [],
   "source": [
    "def simulation_etudiants_survie_mobile_min(P, nb_eleves, X0_eleve, X0_monstre, N):\n",
    "  # Si les élèves et le monstre sont déjà sur la même case (rip)\n",
    "  if X0_eleve==X0_monstre :\n",
    "    return 0\n",
    "  # Initialisation\n",
    "  Xn_eleve = [X0_eleve for i in range (nb_eleves)] #zone actuelle des étudiants\n",
    "  Xn_monstre = X0_monstre #zone actuelle du monstre\n",
    "  # Tours\n",
    "  for t in range(N):\n",
    "    Xn_eleve = [sim_dis(P[Xn_eleve[i]-1], range(1,11), 1)[0] for i in range (nb_eleves)] #déplacement de l'élève\n",
    "    Xn_monstre = sim_dis(P[Xn_monstre-1], range(1,11), 1)[0] #déplacement du monstre\n",
    "    for i in range(nb_eleves):\n",
    "      if Xn_eleve[i]==Xn_monstre : #si l'élève et le monstre sont sur la même case (rip)\n",
    "        return t\n",
    "  return N #l'élève a survécu toute la partie (pendant N tours)\n",
    "\n",
    "M = 1000\n",
    "N = 100\n",
    "X0_eleve = 1\n",
    "X0_monstre = 10\n",
    "nb_eleve = 20\n",
    "\n",
    "L_tps_survie_min_moy = []\n",
    "for i in range (1,nb_eleve+1):\n",
    "  L_tps_survie_min = [simulation_etudiants_survie_mobile_min(P, i, X0_eleve, X0_monstre, N) for _ in range (M)]\n",
    "  moy = np.mean(L_tps_survie_min)\n",
    "  L_tps_survie_min_moy.append(moy)\n",
    "plt.plot([i for i in range (1,nb_eleve+1)], L_tps_survie_min_moy)\n",
    "plt.xlabel(\"Nombre d'élèves au début de la partie\")\n",
    "plt.ylabel(\"Date de la première mort\")\n",
    "plt.title(\"Evolution du temps moyen de la première mort d’un des étudiants\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VlFu2p2OU8wP"
   },
   "source": [
    "On observe que l'évolution du temps avec la première mort est décroissante lorsque le nombre d'étudiants augmente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cy_Fek8LeSUv"
   },
   "source": [
    "Soit $n$ le nombre d'élèves.\\\n",
    "On généralise le procédé étudié en Q.4 avec n élèves et un monstre qui se déplacent.\\\n",
    "Soient les chaînes de Markov $(X_{k,monstre})$, $(X_{k,élève\\ 1})$, ..., $(X_{k,élève\\ n})$ traduisant le déplacement des élèves et du monstre sur les 10 zones en fonction du temps. Ces déplacements sont régis par la matrice stochastique $P$. La suite des $X_k=(X_{k,monstre}, X_{k,élève\\ 1}, ..., X_{k,élève\\ n})$ forme elle-même une chaîne de Markov.\\\n",
    "Soit le temps d'arrêt $\\tau$ défini par :\n",
    "$$\n",
    "\\tau = \\min \\, \\{ k \\geqslant 0 \\; | \\; \\exists m\\in [|1,n|], X_{k,élève\\ m}=X_{k,monstre} \\}\n",
    "$$\n",
    "On cherche ici à calculer : \n",
    "$$\n",
    "\\forall i,j_1,...,j_n \\in [|1, 10|], \\quad \\mathbb{E}_{(i,j_1,...,j_n)}[\\tau] = \\mathbb{E}\\left[ \\tau \\,|\\, X_0 = (i,j_1,...,j_n) \\right]\n",
    "$$\n",
    "\n",
    "D'après le théorème sur le temps moyen d'atteinte, on peut énoncer que $(\\mathbb{E}_{(i,j_1,...,j_n)}[\\tau])_{1\\leq i,j_1,...,j_n \\leq 10}$ est la plus petite solution positive du système suivant :\n",
    "\\begin{equation*}\n",
    "    \\boxed{\n",
    "    \\begin{cases}\n",
    "        y_{(i,j_1,...,j_n)} = 0 & \\text{si } \\exists m\\in[|1,n|] : i = j_m \\\\\n",
    "        y_{(i,j_1,...,j_n)} = 1 + \\displaystyle\\sum_{k\\ne{l_1}\\\\{\\,\\,…}\\\\k\\ne{l_n}} p((i,j_1,...,j_n),(k,l_1,...,l_n)) \\, y_{(k,l_1,...,l_n)} & \\text{sinon}\n",
    "    \\end{cases}\n",
    "    }\n",
    "\\end{equation*}\n",
    "\n",
    "On pose $M$ le nombre de ($n+1$)-ulpets $(i,j_1,...,j_n)$ tels que $\\forall m\\in[|1,n|]$, $i\\ne j_m$.\\\n",
    "On peut alors écrire ce système sous forme matricielle, en notant $b = (1)_{1\\le{n}\\le M}$, $x=(\\mathbb{E}_{(i,j_1,...,j_n)}[\\tau])_{i\\ne j_1,...,i\\ne j_n}$ et $P'=(p((i,j_1,...,j_n),(k,l_1,...,l_n)))_{i\\ne j_1,...,i\\ne j_n,k\\ne l_1,...,k\\ne l_n}$ où $P'$ est une matrice extraite de $P$ :\n",
    "\\begin{align*}\n",
    "    \\forall (i,j_1,…,j_n) \\in \\mathbb N^2,\\, 1 \\le i,j \\le 10, i\\ne j_1,...,i\\ne j_n, \\quad &\\mathbb{E}_{(i,j_1,...,j_n)}[\\tau] = 1 + \\sum_{k\\ne{l}} p((i,j_1,...,j_n),(k,l_1,...,l_n)) \\, \\mathbb{E}_{(k,l_1,...,l_n)}[\\tau] \\\\\n",
    "    \\Longrightarrow \\quad & x = b + P'x \\\\\n",
    "    \\Longrightarrow \\quad &\\boxed{\\left[I_M-P' \\right]x = b}\n",
    "\\end{align*}\n",
    "\n",
    "On remarque, d'après le \\textbf{lemme d'Hadamard}, que la matrice $A = I_M - P'$ est inversible, et on peut alors déterminer les différents valeurs des $\\mathbb{E}_{(i,j)}[\\tau]$.\n",
    "\n",
    "Si, en théorie, le calcul est plutôt similaire, la compléxité de la définition du temps d'arrêt complexifie très grandement la construction de la matrice $P'$ définie plus haut : il est compliqué de trouver efficacement les coefficients de la matrice stochastique à garder pour construire $P'$.\\\n",
    "De plus, les coefficients de la matrice $P$ (et donc de la matrice extraite $P'$) sont de plus en plus petits lorsque $n$ grandi, donc à moins d'avoir la précision nécessaire sur notre machine, la solution par pivot de Gauss est grandement soumise aux erreurs de précision.\n",
    "\n",
    "Ainsi, cette question est plus difficile à aborder, tant sur le plan théorique que sur le plan pratique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xHia_l6KT7QX"
   },
   "source": [
    "## Annexes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1TZTjmpPUGfl"
   },
   "source": [
    "### Théorème du temps moyen d'atteinte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZHXU_JP4Uds9"
   },
   "source": [
    "#### Dans le cadre général"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_GNFQLJeUN1R"
   },
   "source": [
    "Soit $(X_n)_{n\\in \\mathbb N}$ une chaîne de Markov homogène avec comme matrice de transition ${\\displaystyle P = \\left( p_{i,j} \\right)_{(i,j)\\in E^{2}}}$ sur un espace d’état fini ou dénombrable $E$.\n",
    "\n",
    "Soit $A \\subseteq E$, on définit :\n",
    "- Le temps d'atteinte de A par :\n",
    "    \\begin{equation*}\n",
    "        T_A = \\inf\\{ n \\in \\mathbb N \\,|\\, X_n \\in A \\}\n",
    "    \\end{equation*}\n",
    "- Le temps moyen d'atteinte de $A$ partant de $i$\n",
    "    \\begin{equation*}\n",
    "        v_i^A = \\mathbb{E}_i[T_A].\n",
    "    \\end{equation*}\n",
    "\n",
    "On rappelle également que la notation $\\mathbb{P}_i$ (idem pour $\\mathbb{E}_i$) :\n",
    "\\begin{equation*}\n",
    "    \\forall i \\in E, \\text{Pour tout évènement } B, \\quad \\mathbb{P}_i(B) = \\mathbb{P}(B \\,|\\, X_0 = i).\n",
    "\\end{equation*} \\\\\n",
    "\n",
    "Le théorème peut alors s'écrire de cette manière :\n",
    "\n",
    "\\textbf{Théorème du temps moyen d'atteinte}\n",
    "\n",
    "> Le vecteur des temps moyen d'atteinte $(v_i)_{i\\in E}$ est la plus petite solution positive du système\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "        y_i = 0 & \\text{si } i \\in A \\\\\n",
    "        y_i = 1 + \\displaystyle\\sum_{j\\notin A} p_{i,j}\\,y_j & \\text{sinon}\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "\n",
    "\\\\\n",
    "\n",
    "\\textit{Démonstration} :\n",
    "\n",
    "On supposera dans cette démonstration pour simplifier (et car c'est dans le cadre du projet de maths) que $\\mathbb{P}(T_A < \\infty) = 1$. \\\\\n",
    "\n",
    "Montrons tout d'abord que $(v_i)_{i\\in E}$ est solution du système.\n",
    "-  Si $X_0 = i \\in A$ alors on a bien sûr $T_A = 0$ et donc $v_i = \\mathbb{E}_i[T_A] = 0$\n",
    "- Si $X_0 = i \\notin A$ alors on a :\n",
    "    \\begin{equation*}\n",
    "        v_i = \\mathbb{E}_i[T_A] = \\sum_{j\\in E} \\mathbb{E}_i\\left[T_A \\, \\mathbb{1}_{\\{X_1=j\\}} \\right]\n",
    "    \\end{equation*}\n",
    "\n",
    "Et pour tout $j \\in E$, on a:\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}_i\\left[T_A \\, \\mathbb{1}_{\\{X_1=j\\}} \\right] \n",
    "    &= \\left( \\sum_{k\\in\\mathbb{N}^*} k \\, \\mathbb{P}_i(T_A = k, X_1 = j) \\right) \\\\\n",
    "    &= \\left( \\sum_{k\\in\\mathbb{N}^*} k \\, \\mathbb{P}_i(T_A = k \\,|\\, X_1 = j)\\, \\mathbb{P}_i(X_1 = j) \\right) \\tag{formule des probabilités totales} \\\\\n",
    "    &= \\left( \\sum_{k\\in\\mathbb{N}^*} k \\, \\mathbb{P}_j (T_A = k - 1) \\, p_{i,j} \\right) \\tag{par propriété de Markov} \\\\\n",
    "    &= p_{i,j} \\left( \\sum_{k\\in\\mathbb{N}^*} k \\, \\mathbb{P}_j (T_A = k - 1) \\right) \\\\\n",
    "    &= p_{i,j} \\left( \\left( \\sum_{k\\in\\mathbb{N}} k \\, \\mathbb{P}_j(T_A = k) \\right) + \\left( \\sum_{k\\in\\mathbb{N}} \\mathbb{P}_j(T_A = k) \\right) \\right) \\tag{chgt. de var. $k = \\widetilde{k} + 1$} \\\\\n",
    "    &= p_{i,j} \\left(\\mathbb{E}_j[T_A] + 1 \\right)\n",
    "\\end{align*}\n",
    "\n",
    "D'où\n",
    "\\begin{equation*}\n",
    "    \\mathbb{E}_i[T_A] = \\sum_{j\\in E} p_{i,j} \\left(\\mathbb{E}_j[T_A] + 1 \\right) = \\sum_{j\\in E} p_{i,j} + \\sum_{j\\in E} p_{i,j}\\, \\mathbb{E}_j[T_A]\n",
    "\\end{equation*}\n",
    "\n",
    "Et donc :\n",
    "\\begin{equation*}\n",
    "    v_i = 1 + \\sum_{j\\in E} p_{i,j}\\, v_j = 1 + \\sum_{j \\notin A} p_{ij}\\, v_j \\tag{car $v_j = 0$ lorsque $j\\in A$}\n",
    "\\end{equation*}\n",
    "\n",
    "On en conclut donc que $(v_i)_{i\\in E}$ est solution du système. \\\\\n",
    "\n",
    "\n",
    "Montrons maintenant la \\textbf{minimalité} de $(v_i)_{i\\in E}$. Soit $(y_i)_{i\\in E}$ solution du système. Alors si $i \\in A$, on a immédiatement $y_i = 0 = u_i$. Et si $i \\notin A$ on a\n",
    "\\begin{align*}\n",
    "    y_i &= 1 + \\sum_{j \\notin A} p_{i,j} \\,y_j \\\\\n",
    "    &= 1 + \\sum_{j \\notin A} p_{i,j} \\left( 1 + \\sum_{k \\notin A} p_{j,k} \\, y_k \\right) \\\\\n",
    "    &= 1 + \\sum_{j \\notin A} p_{i,j} + \\sum_{j \\notin A} \\sum_{k \\notin A} p_{i,j} \\, p_{j,k}\\, y_k \\tag{car $y_j$ est, lui aussi, solution du système} \\\\\n",
    "    &= \\mathbb{P}_i(T_A \\geq 1) + \\mathbb{P}_i(T_A \\geq 2) + \\sum_{j \\notin A} \\sum_{k \\notin A} p_{i,j}\\, p_{j,k}\\, y_k.\n",
    "\\end{align*}\n",
    "\n",
    "En guise de petite explication de cette dernière ligne, on a $i \\notin A$ donc $\\mathbb{P}_i(T_A \\geq 1) = 1$, et par définition de l'ensemble $A$, et sachant que $i \\notin A$, on a bien : $\\mathbb{P}_i(T_A \\geq 2) = \\sum_{j \\notin A} p_{i,j}$. \\\\\n",
    "\n",
    "Et par récurrence sur $n$ (qu'il faudrait normalement bien rédiger, mais que nous admettrons ici), on obtient que, pour tout $n \\geq 1$\n",
    "\\begin{align*}\n",
    "    y_i &= \\sum_{k=1}^{n} \\mathbb{P}_i(T_A \\geq k) + \\sum_{j_1 \\notin A} \\sum_{j_2 \\notin A} \\dots \\sum_{j_n \\notin A} p_{i,j_1} \\, p_{j_1,j_2} \\dots p_{j_{n-1},j_n} \\,y_{j_n}.\n",
    "\\end{align*}\n",
    "\n",
    "On a de plus supposé que $y_i \\geq 0$ pour tout $i \\in E$ (car on a posée $(y_i)_{i \\in E}$ comme solution positive du système), d'où :\n",
    "\\begin{equation*}\n",
    "    y_k \\geq \\sum_{k=1}^{n} \\mathbb{P}_i(T_A \\geq k)\n",
    "\\end{equation*}\n",
    "\n",
    "Ceci étant vrai pour tout $n \\geq 1$, on a :\n",
    "\\begin{equation*}\n",
    "    y_i \\geq \\sum_{k=1}^{+\\infty} \\mathbb{P}_i(T_A \\geq k)\n",
    "\\end{equation*}\n",
    "\n",
    "et le passage à la limite est autorisé car la suite $\\left(\\displaystyle\\sum_{k=1}^{n} \\mathbb{P}_i(T_A \\geq k) \\right)_{n\\geq 1}$ est croissante.\n",
    "\n",
    "De plus, par propriété de l'espérance dans le cadre des variables aléatoires discrètes :\n",
    "\\begin{equation*}\n",
    "    \\sum_{k=1}^{+ \\infty} \\mathbb{P}(T_A \\geq k) = \\sum_{k=1}^{\\infty} k \\,\\mathbb{P}(T_A = k) = \\mathbb{E}_i(T_A)\n",
    "\\end{equation*}\n",
    "\n",
    "Donc $\\boxed{\\forall i \\in E, \\quad y_i \\geq \\mathbb{E}_i(T_A) = v_i}$. \n",
    "\n",
    "Et ainsi, le vecteur des temps moyen d'atteinte $(v_i)_{i\\in E}$ est \\textbf{la plus petite solution positive du système}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "irSTTObPVrPg"
   },
   "source": [
    "#### Dans le cadre d'un couple de chaînes de Markov"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PrcqtqCGV08T"
   },
   "source": [
    "On note ici $E = [| 1, 10 |]^2$, et $A = \\{ (i,j) \\in E \\,|\\, i=j \\}$.\n",
    "\n",
    "On s'intéresse ici à la suite des $X_k=(X_{k,\\text{monstre}}, X_{k,\\text{élève}})$, qui forme elle-même une chaîne de Markov.\n",
    "\n",
    "Le théorème du temps moyen d'atteinte peut alors s'écrire de cette manière :\n",
    "\n",
    "\\textbf{Théorème du temps moyen d'atteinte} :\n",
    "\n",
    "> Le vecteur des temps moyen d'atteinte $(v_{(i,j)})_{(i,j) \\in E}$ est la plus petite solution positive du système\n",
    "\\begin{equation*}\n",
    "    \\begin{cases}\n",
    "        y_{(i,j)} = 0 & \\text{si } i \\in A \\\\\n",
    "        y_{(i,j)} = 1 + \\displaystyle\\sum_{(k,l) \\notin A} p_{(i,j)\\to (k,l)}\\,y_{(k,l)} & \\text{sinon}\n",
    "    \\end{cases}\n",
    "\\end{equation*}\n",
    "    \n",
    "\\\\\n",
    "\n",
    "\\textit{Démonstration} :\n",
    "\n",
    "On supposera dans cette démonstration pour simplifier (et car c'est dans le cadre du projet de maths) que $\\mathbb{P}(T_A < \\infty) = 1$. \\\\\n",
    "\n",
    "Montrons tout d'abord que $(v_{(i,j)})_{(i,j)\\in E}$ est solution du système.\n",
    "- Si $X_0 = (i,j) \\in A$ alors on a bien sûr $T_A = 0$ et donc $v_{(i,j)} = \\mathbb{E}_{(i,j)}[T_A] = 0$\n",
    "- Si $X_0 = (i,j) \\notin A$ alors on a :\n",
    "    \\begin{equation*}\n",
    "        v_{(i,j)} = \\mathbb{E}_{(i,j)}[T_A] = \\sum_{(k,l)\\in E} \\mathbb{E}_{(i,j)}\\left[T_A \\, \\mathbb{1}_{\\{X_1=(k,l)\\}} \\right]\n",
    "    \\end{equation*}\n",
    "\n",
    "Et pour tout $(k,l) \\in E$, on a:\n",
    "\\begin{align*}\n",
    "    \\mathbb{E}_{(i,j)}\\left[T_A \\, \\mathbb{1}_{\\{X_1=(k,l)\\}} \\right] \n",
    "    &= \\left( \\sum_{n\\in\\mathbb{N}^*} n \\, \\mathbb{P}_{(i,j)}(T_A = k, X_1 = (k,l)) \\right) \\\\\n",
    "    &= \\left( \\sum_{n\\in\\mathbb{N}^*} n \\, \\mathbb{P}_{(i,j)}(T_A = k \\,|\\, X_1 = (k,l))\\, \\mathbb{P}_{(i,j)}(X_1 = (k,l)) \\right) \\tag{probabilités totales} \\\\\n",
    "    &= \\left( \\sum_{n\\in\\mathbb{N}^*} n \\, \\mathbb{P}_{(k,l)} (T_A = n - 1) \\, p_{(i,j)\\to (k,l)} \\right) \\tag{par propriété de Markov} \\\\\n",
    "    &= p_{(i,j)\\to (k,l)} \\left( \\sum_{n\\in\\mathbb{N}^*} n \\, \\mathbb{P}_{(k,l)}(T_A = n - 1) \\right) \\\\\n",
    "    &=p_{(i,j)\\to (k,l)} \\left( \\left( \\sum_{n\\in\\mathbb{N}} n \\, \\mathbb{P}_{(k,l)}(T_A = n) \\right) + \\left( \\sum_{n\\in\\mathbb{N}} \\mathbb{P}_{(k,l)}(T_A = n) \\right) \\right) \\tag{chgt. de var. $n = \\widetilde{n} + 1$} \\\\\n",
    "    &=p_{(i,j)\\to (k,l)} \\left(\\mathbb{E}_{(k,l)}[T_A] + 1 \\right)\n",
    "\\end{align*}\n",
    "\n",
    "D'où\n",
    "\\begin{equation*}\n",
    "    \\mathbb{E}_{(i,j)}[T_A] = \\sum_{j\\in E} p_{(i,j)\\to (k,l)} \\left(\\mathbb{E}_{(k,l)}[T_A] + 1 \\right) = \\sum_{(k,l)\\in E} p_{(i,j)\\to (k,l)} + \\sum_{(k,l)\\in E} p_{(i,j)\\to (k,l)}\\, \\mathbb{E}_{(k,l)}[T_A]\n",
    "\\end{equation*}\n",
    "\n",
    "Et donc :\n",
    "\\begin{equation*}\n",
    "    v_{(i,j)} = 1 + \\sum_{(k,l)\\in E} p_{(i,j)\\to (k,l)}\\, v_{(k,l)} = 1 + \\sum_{(k,l) \\notin A} p_{(i,j)\\to (k,l)}\\, v_{(k,l)} \\tag{car $v_{(k,l)} = 0$ lorsque $(k,l)\\in A$}\n",
    "\\end{equation*}\n",
    "\n",
    "On en conclut donc que $(v_{(i,j)})_{(i,j)\\in E}$ est solution du système. \\\\\n",
    "\n",
    "La minimalité de $(v_{(i,j)})_{(i,j)\\in E}$ se montre de la même manière que dans le cas plus classique. (On se passera donc de la réécriture en adaptant seulement les notations.) \\\\\n",
    "\n",
    "Ainsi, le vecteur des temps moyen d'atteinte $(v_{(i,j)})_{(i,j)\\in E}$ est \\textbf{la plus petite solution positive du système}."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
